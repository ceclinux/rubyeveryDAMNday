{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count word(naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{:module, Timemeasure, <<70, 79, 82, 49, 0, 0, 4, 236, 66, 69, 65, 77, 65, 116, 85, 56, 0, 0, 0, 173, 0, 0, 0, 17, 18, 69, 108, 105, 120, 105, 114, 46, 84, 105, 109, 101, 109, 101, 97, 115, 117, 114, 101, 8, 95, 95, 105, ...>>, {:count_time, 1}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defmodule Timemeasure do\n",
    "  def count_time(func) do\n",
    "    start_time = Time.utc_now()\n",
    "    func.()\n",
    "    end_time = Time.utc_now()\n",
    "    Time.diff(end_time, start_time, :microsecond)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the implementation above is not very efficient, as Enum.flat_map/2 will build a list with all the words in the document before reducing it. If the document is, for example, 2GB, we will load 2GB of data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15164215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defmodule CountWord do\n",
    "  def naive_version do\n",
    "    File.read!(\"/home/demouser/Notes/shakespeare.txt\")\n",
    "    |> String.split(\"\\n\")\n",
    "    |> Enum.flat_map(fn line ->\n",
    "        String.split(line, \" \")\n",
    "       end)\n",
    "    |> Enum.reduce(%{}, fn word, acc ->\n",
    "        Map.update(acc, word, 1, & &1 + 1)\n",
    "       end)\n",
    "    |> Enum.to_list()\n",
    "  end\n",
    "end\n",
    "\n",
    "Timemeasure.count_time(&CountWord.naive_version/0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of loading the whole set into memory, we will only keep the current line in memory while we process it. While this allows us to process the whole data set efficiently, it does not leverage concurrency. Flow solves that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "~T[13:23:06.153086]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Time.utc_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "~T[13:23:06.229813]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Time.utc_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76727"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time.diff(b, a, :microsecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{:module, CountWord, <<70, 79, 82, 49, 0, 0, 7, 100, 66, 69, 65, 77, 65, 116, 85, 56, 0, 0, 1, 67, 0, 0, 0, 28, 16, 69, 108, 105, 120, 105, 114, 46, 67, 111, 117, 110, 116, 87, 111, 114, 100, 8, 95, 95, 105, 110, 102, ...>>, {:stream_version, 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defmodule CountWord do\n",
    "  def stream_version do\n",
    "File.stream!(\"/home/demouser/Notes/shakespeare.txt\")\n",
    "|> Stream.flat_map(fn line ->\n",
    "    String.split(line, \" \")\n",
    "   end)\n",
    "|> Enum.reduce(%{}, fn word, acc ->\n",
    "    Map.update(acc, word, 1, & &1 + 1)\n",
    "   end)\n",
    "|> Enum.to_list()\n",
    "end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10087096"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Timemeasure.count_time(&CountWord.stream_version/0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line_or_bytes argument configures how the file is read when streaming, by :line (default) or by a given number of bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert from Stream to Flow, we have made two changes:\n",
    "\n",
    "1. We have replaced the calls to `Stream` to `Flow`\n",
    "2. We call `partition/1` so words are properly partitined between stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedFunctionError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "** %UndefinedFunctionError{arity: 1, exports: nil, function: :from_enumerable, module: Flow, reason: nil}"
     ]
    }
   ],
   "source": [
    "File.stream!(\"/home/demouser/Notes/shakespeare.txt\")\n",
    "|> Flow.from_enumerable()\n",
    "|> Flow.flat_map(&String.split(&1, \" \"))\n",
    "|> Flow.partition()\n",
    "|> Flow.reduce(fn -> %{} end, fn word, acc ->\n",
    "  Map.update(acc, word, 1, & &1 + 1)\n",
    "end)\n",
    "|> Enum.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "850000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above will use all available cores and will keep an ongoing flow of data instead of traversing them line by line. Once all data is computed, it is sent to process which invoded `Enum.to_list/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Elixir",
   "language": "Elixir",
   "name": "ielixir"
  },
  "language_info": {
   "codemirror_mode": "elixir",
   "file_extension": "ex",
   "mimetype": "text/x-elixir",
   "name": "elixir",
   "nbconvert_exporter": "",
   "pygments_lexer": "elixir",
   "version": "#Version<1.6.5>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
