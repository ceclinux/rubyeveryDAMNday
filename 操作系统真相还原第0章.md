## 访问外部硬件有两个方式

1. 将某个外设的内存映射到一定范围的地址空间中， CPU通过地址总线访问该内存区域时会落到外设的内存中，这种映射让CPU访问外设的内存就如同访问主板上的物理内存一样。

2. 外设通过IO接口与CPU通信，CPU访问外设，就是访问IO接口，由IO接口将信息传递给另一端的外设，也就是说，CPU从来不知道有这些设备的存在，它只知道自己操作的IO接口。
 
 编译器提供了一套库函数，库函数又有封装的系统调用，这样的代码称之为运行库。C语言的运行库称为**C运行库**，就是所谓的CRT（C Runtime Library)

应用程序加上操作系统提供功能才算是完整的程序。用户进程陷入内核态是指：由于内部或外部中断发生，当前进程被暂时中止执行，其下上文被内的的终端程序保存以来后，开始执行一段内核的代码。

当应用程序陷入内核之后，他自己以及下CPU了，以后发生的事，应用程序完全不知道，它的上下文环境已经被保存到自己的0特权级栈中了，那时在CPU上运行的程序已经是内核程序了。

对于Linux系统来说，直接嵌入会变代码`int 80`即可执行系统调用。

如果把软件分层的话，最外圈是应用程序，里面是操作系统。应用程序处于特权级3，操作系统处于特权级0。当用户程序欲访问系统资源时（无论是硬件，还是内核数据结构），它需要进行系统调用。这样CPU进入了内核态，也称管态。

CPU采用“段基址 + 段内偏移地址”的形式访问内存，就需要专门提供段基址寄存器。程序中需要用到哪块内存，只要先加载合适的段到段基址寄存器中，再给出相对于该段基址的便宜地址便可，CPU中的地址单元会将这两个地址相加后的结果用于内存访问，送上地址总线。

举个例子，假设段基址为`0xC00`，要想访问物理内存`0xC01`，就要将用`0xC01:0x00`的方式来访问。同样，若要访问物理内存`0xC04`，段基址和段内偏移的组合可以是`0xC01:0x03`、`0xC02:0x02`、`0xC00:0xC04`等等，总之想要访问某个物理地址，只要凑出合适的段基地址和段内偏移地址，其和为该物理地址就行了。

说了那么多，我想告诉你的是只要程序分了段，吧整个段平移到任何位置后，段内的地址相对于段基址是不变的，无论段基址是多少，只要给出段内偏移地址，CPU就能访问正确的指令。于是加载用户程序时，因为程序中用的是段内偏移地址，相对于新的段基址，该偏移地址出的内存内容还是一样的。

Flat memory model or linear memory model refers to a memory addressing paradigm in which "memory appears to the program as a single contiguous address space."[1] The CPU can directly (and linearly) address all of the available memory locations without having to resort to any sort of memory segmentation or paging schemes.

Memory management and address translation can still be implemented on top of a flat memory model in order to facilitate the operating system's functionality, resource protection, multitasking or to increase the memory capacity beyond the limits imposed by the processor's physical address space, but the key feature of a flat memory model is that the entire memory space is linear, sequential and contiguous from address zero to MaxBytes − 1.

对于代码中的分段，有的是操作系统做的，有的是程序员自己划分的。如果在多段模型下编程，我们必然会在源码中定义多个段，然后不断地切换寄存器指向的段，这样才能访问到不同段中的数据。所以说，在多段模型下的程序分段是程序员认为划分的。如果在平坦模型下变成，操作系统将整个4GB内存都放在同一个段中，我们就不需要来回切换段寄存器所指向的段。对于代码中是否要分段，这取决于操作系统是否在平坦模型下。

地址0出的指令是`move ds, ax`，其机器码是`8ED8`，这是十六进制表示，可见其大小是2字节。前面说过，下一条指令的地址是按照前面指令的尺寸拍下来的，那第二行指令的其实地址是`0+2=2`，这不是我故意写上去的，编译器真的就是这样编排的。第2条的指令是`mov ax, [0x7]`，其机器码是`A10700`，这是3字节大小。所以第3条指令的地址是`2+3=5`。后面的指令地址也是这样推算的。

```assembly
jmp start
var dd 1 ;定义变量var并赋值为1。分配变量不是CPU的工作
         ;汇编器负责分配空间并为变量
start:
mov ax, 0 ;将ax赋值为0
```

如果将上面的汇编代码按纯二进制编译，如果不加第1行的`jmp`，CPU也许会发出异常，显示无效指令，也许不知道执行到哪里去了。因为CPU只会执行`cs:ip`中的指令，这两个寄存器记录的是吓一跳带执行指令的地址，以一个地址`var`处的值为1，显然我们从定义中看出这只是数据，但指令和数据都是二进制数字，CPU可分不出这是指令，还是数据。保不准，某些数据误打误撞悄悄是某种指令也说不定。

将数据和代码分开的好处有三点：

1. 数据本身是需要被修改的，所以数据就需要有可写的属性，代码段必须是只读的

```
A common example is matrix multiplication:

for i in 0..n
  for j in 0..m
    for k in 0..p
      C[i][j] = C[i][j] + A[i][k] * B[k][j];
By switching the looping order for j and k, the speedup in large matrix multiplications becomes dramatic, at least for languages that put contiguous array elements in the last dimension. This will not change the mathematical result, but it improves efficiency. In this case, "large" means, approximately, more than 100,000 elements in each matrix, or enough addressable memory such that the matrices will not fit in L1 and L2 caches.

for i in 0..n
  for k in 0..p
    for j in 0..m
      C[i][j] = C[i][j] + A[i][k] * B[k][j];
The reason for this speed up is that in the first case, the reads of A[i][k] are in cache (since the k index is the contiguous, last dimension), but B[k][j] is not, so there is a cache miss penalty on B[k][j]. C[i][j] is irrelevant, because it can be factored out of the inner loop. In the second case, the reads and writes of C[i][j] are both in cache, the reads of B[k][j] are in cache, and the read of A[i][k] can be factored out of the inner loop. Thus, the second example has no cache miss penalty in the inner loop while the first example has a cache penalty.
```
